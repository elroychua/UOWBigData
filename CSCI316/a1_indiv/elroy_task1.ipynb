{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment 1 Task 1\n",
        "\n",
        "<strong>Name:</strong> Elroy Chua Ming Xuan </br>\n",
        "<strong>UOW ID:</strong> 7431673\n",
        "<strong>Data Set:</strong> Customer Churn Dataset\n",
        "https://www.kaggle.com/datasets/muhammadshahidazeem/customer-churn-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 1: Create one Pandas dataframe from the two CSV files\n",
        "In order to merge the training and test data, first, we will load both data sets using Pandas, and then we will concatenate them into a single dataframe. Assume that we have two files, train.csv and test.csv, from the given link. Below is the Python code to perform this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data\n",
            "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
            "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
            "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
            "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
            "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
            "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
            "\n",
            "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
            "0           18.0          Standard          Annual        932.0   \n",
            "1            8.0             Basic         Monthly        557.0   \n",
            "2           18.0             Basic       Quarterly        185.0   \n",
            "3            7.0          Standard         Monthly        396.0   \n",
            "4            8.0             Basic         Monthly        617.0   \n",
            "\n",
            "   Last Interaction  Churn  \n",
            "0              17.0    1.0  \n",
            "1               6.0    1.0  \n",
            "2               3.0    1.0  \n",
            "3              29.0    1.0  \n",
            "4              20.0    1.0  \n",
            "CustomerID           1\n",
            "Age                  1\n",
            "Gender               1\n",
            "Tenure               1\n",
            "Usage Frequency      1\n",
            "Support Calls        1\n",
            "Payment Delay        1\n",
            "Subscription Type    1\n",
            "Contract Length      1\n",
            "Total Spend          1\n",
            "Last Interaction     1\n",
            "Churn                1\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "# Load the train_train_train_data\n",
        "df_test = pd.read_csv('customer_churn_dataset-testing-master.csv')\n",
        "df_train = pd.read_csv('customer_churn_dataset-training-master.csv')\n",
        "\n",
        "# Concatenate the dataframes\n",
        "df = pd.concat([df_train, df_test], ignore_index=True)\n",
        "\n",
        "#Data\n",
        "print(\"Data\")\n",
        "# Inspect the first few rows of the dataset\n",
        "df.head()\n",
        "\n",
        "# Identify missing values\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 2: Once missing values are identified, remove the missing values from the dataset.\n",
        "Missing data can be identified with the isna() function in Pandas (refer to previous cell). To clean missing values, we can use various imputation methods like mean, median, mode imputation, or more advanced techniques like using regression models. For this case we will use .dropna() to remove the missing values from the dataset as it is a row of missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check for missing values after dropping data\n",
            "CustomerID           0\n",
            "Age                  0\n",
            "Gender               0\n",
            "Tenure               0\n",
            "Usage Frequency      0\n",
            "Support Calls        0\n",
            "Payment Delay        0\n",
            "Subscription Type    0\n",
            "Contract Length      0\n",
            "Total Spend          0\n",
            "Last Interaction     0\n",
            "Churn                0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# If there are missing values, we drop them\n",
        "df.dropna(inplace=True)\n",
        "# Dropping the missing values\n",
        "print(\"Check for missing values after dropping data\")\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 3: Perform z-score normalization of the values in the attribute “Last Interaction”. Show the mean and variance of the normalized values\n",
        "Z-score normalization is a scaling method that transforms the data into a distribution with a mean of 0 and a standard deviation of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-7.831066837512298e-17\n",
            "0.9999999999999998\n"
          ]
        }
      ],
      "source": [
        "# Z-score normalization\n",
        "df['Last Interaction Normalized'] = (\n",
        "    df['Last Interaction'] - df['Last Interaction'].mean()) / df['Last Interaction'].std()\n",
        "\n",
        "# Print the mean and variance\n",
        "print(df['Last Interaction Normalized'].mean())\n",
        "print(df['Last Interaction Normalized'].var())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 4: Create five bins for the attribute “Total Spend” such that the bins contain (approximately) equivalent numbers of records.\n",
        "We can use the qcut function from pandas which creates bins of equal size based on the quantiles of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Spend Bins\n",
            "(99.999, 378.0]    101271\n",
            "(719.0, 859.0]     101223\n",
            "(578.0, 719.0]     101069\n",
            "(378.0, 578.0]     100822\n",
            "(859.0, 1000.0]    100821\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Create bins\n",
        "df['Total Spend Bins'] = pd.qcut(df['Total Spend'], q=5)\n",
        "# Check the bins\n",
        "print(df['Total Spend Bins'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 5: Apply one-hot-encoding to the attribute “Contract Length”.\n",
        "One-hot encoding is a process of converting categorical data variables so they can be provided to machine learning algorithms to improve predictions. Pandas provides get_dummies function which is used to convert categorical variable into dummy/indicator variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['CustomerID', 'Age', 'Gender', 'Tenure', 'Usage Frequency',\n",
            "       'Support Calls', 'Payment Delay', 'Subscription Type',\n",
            "       'Contract Length', 'Total Spend', 'Last Interaction', 'Churn',\n",
            "       'Last Interaction Normalized', 'Total Spend Bins',\n",
            "       'Contract Length_Annual', 'Contract Length_Monthly',\n",
            "       'Contract Length_Quarterly'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# One-hot encoding\n",
        "df = pd.concat(\n",
        "    [df, pd.get_dummies(df['Contract Length'], prefix='Contract Length')], axis=1)\n",
        "\n",
        "# Check the new columns\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Step 6: Define at least one new attribute based on existing attribute, and explain your reason behind your definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Usage Frequency</th>\n",
              "      <th>Support Calls</th>\n",
              "      <th>Payment Delay</th>\n",
              "      <th>Subscription Type</th>\n",
              "      <th>Contract Length</th>\n",
              "      <th>Total Spend</th>\n",
              "      <th>Last Interaction</th>\n",
              "      <th>Churn</th>\n",
              "      <th>Last Interaction Normalized</th>\n",
              "      <th>Total Spend Bins</th>\n",
              "      <th>Contract Length_Annual</th>\n",
              "      <th>Contract Length_Monthly</th>\n",
              "      <th>Contract Length_Quarterly</th>\n",
              "      <th>Spend per Month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>39.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Standard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>932.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.277572</td>\n",
              "      <td>(859.0, 1000.0]</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>65.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Basic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>557.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.000267</td>\n",
              "      <td>(378.0, 578.0]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>Basic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>185.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.348768</td>\n",
              "      <td>(99.999, 378.0]</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>38.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Standard</td>\n",
              "      <td>NaN</td>\n",
              "      <td>396.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.671578</td>\n",
              "      <td>(378.0, 578.0]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>32.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Basic</td>\n",
              "      <td>NaN</td>\n",
              "      <td>617.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.626073</td>\n",
              "      <td>(578.0, 719.0]</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
              "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
              "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
              "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
              "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
              "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
              "\n",
              "   Payment Delay Subscription Type  Contract Length  Total Spend  \\\n",
              "0           18.0          Standard              NaN        932.0   \n",
              "1            8.0             Basic              NaN        557.0   \n",
              "2           18.0             Basic              NaN        185.0   \n",
              "3            7.0          Standard              NaN        396.0   \n",
              "4            8.0             Basic              NaN        617.0   \n",
              "\n",
              "   Last Interaction  Churn  Last Interaction Normalized Total Spend Bins  \\\n",
              "0              17.0    1.0                     0.277572  (859.0, 1000.0]   \n",
              "1               6.0    1.0                    -1.000267   (378.0, 578.0]   \n",
              "2               3.0    1.0                    -1.348768  (99.999, 378.0]   \n",
              "3              29.0    1.0                     1.671578   (378.0, 578.0]   \n",
              "4              20.0    1.0                     0.626073   (578.0, 719.0]   \n",
              "\n",
              "   Contract Length_Annual  Contract Length_Monthly  Contract Length_Quarterly  \\\n",
              "0                    True                    False                      False   \n",
              "1                   False                     True                      False   \n",
              "2                   False                    False                       True   \n",
              "3                   False                     True                      False   \n",
              "4                   False                     True                      False   \n",
              "\n",
              "   Spend per Month  \n",
              "0              NaN  \n",
              "1              NaN  \n",
              "2              NaN  \n",
              "3              NaN  \n",
              "4              NaN  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert Contract Length to numeric (float) type\n",
        "df['Contract Length'] = pd.to_numeric(df['Contract Length'], errors='coerce')\n",
        "#5. Apply one-hot-encoding to the attribute “Contract Length”.\n",
        "df['Spend per Month'] = df['Total Spend'] / df['Contract Length']\n",
        "#Display first 5 rows of the data frame after the transformation.\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assignment 1 Task 2\n",
        "The objective of this task is to implement from scratch a Decision Tree classifier to predict the churn label.\n",
        "You cannot use any ML library for this task."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.10 ('testEnv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "96f8c630555ca8c8517ffff7a44c42c100b07707e04e471dc387e2341790e389"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
