{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Assignment 1 Task 2\n",
    "\n",
    "### Name: Calaunan Alexander Jr Sumampong\n",
    "\n",
    "### UOW ID: 7559161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'customer_churn_dataset-training-master.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Import data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mcustomer_churn_dataset-training-master.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mcustomer_churn_dataset-testing-master.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# Concatenate train and test data\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'customer_churn_dataset-training-master.csv'"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "train_df = pd.read_csv('customer_churn_dataset-training-master.csv')\n",
    "test_df = pd.read_csv('customer_churn_dataset-testing-master.csv')\n",
    "\n",
    "# Concatenate train and test data\n",
    "df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Get info on data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See head of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Usage Frequency</th>\n",
       "      <th>Support Calls</th>\n",
       "      <th>Payment Delay</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Contract Length</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Last Interaction</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Annual</td>\n",
       "      <td>932.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>557.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>396.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>617.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
       "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
       "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
       "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
       "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
       "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
       "\n",
       "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
       "0           18.0          Standard          Annual        932.0   \n",
       "1            8.0             Basic         Monthly        557.0   \n",
       "2           18.0             Basic       Quarterly        185.0   \n",
       "3            7.0          Standard         Monthly        396.0   \n",
       "4            8.0             Basic         Monthly        617.0   \n",
       "\n",
       "   Last Interaction  Churn  \n",
       "0              17.0    1.0  \n",
       "1               6.0    1.0  \n",
       "2               3.0    1.0  \n",
       "3              29.0    1.0  \n",
       "4              20.0    1.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "1.0    280492\n",
       "0.0    224714\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the values of the Y variable\n",
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some information:\n",
    "- Target Variable is <u>**binary**</u>\n",
    "- 1 row of null values\n",
    "- Some columns are object type\n",
    "    - Gender, Subscription Type, Contract Length are nominal data\n",
    "    - One-Hot-Encoding required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the null valued row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505206 entries, 0 to 505206\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   CustomerID         505206 non-null  int64 \n",
      " 1   Age                505206 non-null  int64 \n",
      " 2   Gender             505206 non-null  object\n",
      " 3   Tenure             505206 non-null  int64 \n",
      " 4   Usage Frequency    505206 non-null  int64 \n",
      " 5   Support Calls      505206 non-null  int64 \n",
      " 6   Payment Delay      505206 non-null  int64 \n",
      " 7   Subscription Type  505206 non-null  object\n",
      " 8   Contract Length    505206 non-null  object\n",
      " 9   Total Spend        505206 non-null  int64 \n",
      " 10  Last Interaction   505206 non-null  int64 \n",
      " 11  Churn              505206 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 50.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Delete the single null row\n",
    "df= df.dropna()\n",
    "\n",
    "# Convert the feature types back to int64\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "        df[col] = df[col].astype('int64')\n",
    "\n",
    "# Check for missing values inside the data sets\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the values of the nominal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "Male      280273\n",
      "Female    224933\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Subscription Type\n",
      "Standard    170630\n",
      "Premium     170099\n",
      "Basic       164477\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Contract Length\n",
      "Annual       198608\n",
      "Quarterly    197364\n",
      "Monthly      109234\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Gender'].value_counts())\n",
    "print()\n",
    "print(df['Subscription Type'].value_counts())\n",
    "print()\n",
    "print(df['Contract Length'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode the nominal columns on the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Tenure  Usage Frequency  Support Calls  Payment Delay  \\\n",
      "0           2   30      39               14              5             18   \n",
      "1           3   65      49                1             10              8   \n",
      "2           4   55      14                4              6             18   \n",
      "3           5   58      38               21              7              7   \n",
      "4           6   23      32               20              5              8   \n",
      "\n",
      "   Total Spend  Last Interaction  Churn  Gender_Female  Gender_Male  \\\n",
      "0          932                17      1              1            0   \n",
      "1          557                 6      1              1            0   \n",
      "2          185                 3      1              1            0   \n",
      "3          396                29      1              0            1   \n",
      "4          617                20      1              0            1   \n",
      "\n",
      "   Subscription Type_Basic  Subscription Type_Premium  \\\n",
      "0                        0                          0   \n",
      "1                        1                          0   \n",
      "2                        1                          0   \n",
      "3                        0                          0   \n",
      "4                        1                          0   \n",
      "\n",
      "   Subscription Type_Standard  Contract Length_Annual  \\\n",
      "0                           1                       1   \n",
      "1                           0                       0   \n",
      "2                           0                       0   \n",
      "3                           1                       0   \n",
      "4                           0                       0   \n",
      "\n",
      "   Contract Length_Monthly  Contract Length_Quarterly  \n",
      "0                        0                          0  \n",
      "1                        1                          0  \n",
      "2                        0                          1  \n",
      "3                        1                          0  \n",
      "4                        1                          0  \n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505206 entries, 0 to 505206\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count   Dtype\n",
      "---  ------                      --------------   -----\n",
      " 0   CustomerID                  505206 non-null  int64\n",
      " 1   Age                         505206 non-null  int64\n",
      " 2   Tenure                      505206 non-null  int64\n",
      " 3   Usage Frequency             505206 non-null  int64\n",
      " 4   Support Calls               505206 non-null  int64\n",
      " 5   Payment Delay               505206 non-null  int64\n",
      " 6   Total Spend                 505206 non-null  int64\n",
      " 7   Last Interaction            505206 non-null  int64\n",
      " 8   Churn                       505206 non-null  int64\n",
      " 9   Gender_Female               505206 non-null  int64\n",
      " 10  Gender_Male                 505206 non-null  int64\n",
      " 11  Subscription Type_Basic     505206 non-null  int64\n",
      " 12  Subscription Type_Premium   505206 non-null  int64\n",
      " 13  Subscription Type_Standard  505206 non-null  int64\n",
      " 14  Contract Length_Annual      505206 non-null  int64\n",
      " 15  Contract Length_Monthly     505206 non-null  int64\n",
      " 16  Contract Length_Quarterly   505206 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 69.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Manually one-hot encoding the 'Gender' feature using pd.get_dummies(), make sure columns are int64\n",
    "\n",
    "df_encoded = pd.get_dummies(df, columns=['Gender', 'Subscription Type', 'Contract Length'], dtype='int64')\n",
    "\n",
    "print(df_encoded.head())\n",
    "print() \n",
    "df_encoded.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START DEFINING THE DECISION TREE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE NODE CLASS\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, info_gain=None, leaf_value=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        \n",
    "        # leaf nodes\n",
    "        self.leaf_value = leaf_value\n",
    "\n",
    "# DEFINE DECISION TREE CLASS\n",
    "class DecisionTree():\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, criterion='info_gain'):\n",
    "        self.root = None\n",
    "        # stopping conditions\n",
    "        self.min_samples_split = min_samples_split  # minimum number of samples required to split an internal node\n",
    "        self.max_depth = max_depth  # maximum depth of the tree\n",
    "        self.criterion = criterion  # criterion to measure the quality of a split (gini_index, gain_ratio, info_gain)\n",
    "\n",
    "    # TYPES OF CRITERION:\n",
    "    # FOR INFO GAIN\n",
    "    def entropy(self, y):\n",
    "        entropy = 0\n",
    "        unique_values = set(y)\n",
    "\n",
    "        # get the probability of each value\n",
    "        for value in unique_values:\n",
    "            p = sum(y == value) / len(y)    \n",
    "            entropy -= p * np.log2(p)\n",
    "        return entropy\n",
    "    \n",
    "    def information_gain(self, y, y_left, y_right):\n",
    "        entropy_parent = self.entropy(y)\n",
    "        entropy_children = (len(y_left) / len(y)) * self.entropy(y_left) + (len(y_right) / len(y)) * self.entropy(y_right)\n",
    "        return entropy_parent - entropy_children\n",
    "    \n",
    "    # FOR GINI INDEX\n",
    "    def gini_index(self, y):\n",
    "        gini_index = 1\n",
    "        unique_values = set(y)\n",
    "\n",
    "        # get the probability of each value\n",
    "        for value in unique_values:\n",
    "            p = sum(y == value) / len(y)\n",
    "            gini_index -= p ** 2\n",
    "        return gini_index\n",
    "    \n",
    "    # FOR GAIN RATIO\n",
    "    def gain_ratio(self, y, y_left, y_right):\n",
    "        information_gain = self.information_gain(y, y_left, y_right)\n",
    "        split_info = self.entropy(y)\n",
    "        return information_gain / split_info\n",
    "    \n",
    "    def best_split(self, X, y):\n",
    "        # best_split = (feature index, split value, information gain)\n",
    "        best_split = (None, None, 0)\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            X_feature = X[:, feature]\n",
    "            unique_values = set(X_feature)\n",
    "            for value in unique_values:\n",
    "                y_left = y[X_feature <= value]\n",
    "                y_right = y[X_feature > value]\n",
    "                if self.criterion == 'gini_index':\n",
    "                    info_gain = self.gini_index(y) - (len(y_left) / len(y)) * self.gini_index(y_left) - (len(y_right) / len(y)) * self.gini_index(y_right)\n",
    "                elif self.criterion == 'gain_ratio':\n",
    "                    info_gain = self.gain_ratio(y, y_left, y_right)\n",
    "                elif self.criterion == 'info_gain':\n",
    "                    info_gain = self.information_gain(y, y_left, y_right)\n",
    "                else:\n",
    "                    raise ValueError('Invalid criterion')\n",
    "                if info_gain > best_split[2]:\n",
    "                    best_split = (feature, value, info_gain)\n",
    "        return best_split\n",
    "    \n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        # Prevent further splitting if stopping conditions are met\n",
    "        if (depth >= self.max_depth) or (len(y) < self.min_samples_split) or (len(np.unique(y)) == 1):\n",
    "            leaf_value = np.bincount(y.astype(int)).argmax()  # Convert y to integers before using bincount\n",
    "            return Node(leaf_value=leaf_value)\n",
    "        \n",
    "        # Continue splitting the data if stopping conditions are not met\n",
    "        feature, value, info_gain = self.best_split(X, y)  # find the best split point\n",
    "        X_left, y_left = X[X[:, feature] <= value], y[X[:, feature] <= value]\n",
    "        X_right, y_right = X[X[:, feature] > value], y[X[:, feature] > value]\n",
    "\n",
    "        # Recursively build the subtrees\n",
    "        left = self.build_tree(X_left, y_left, depth + 1)\n",
    "        right = self.build_tree(X_right, y_right, depth + 1)\n",
    "        return Node(feature=feature, value=value, left=left, right=right, info_gain=info_gain)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "    \n",
    "    def _predict(self, x):\n",
    "        node = self.root\n",
    "        while node.leaf_value is None:\n",
    "            if x[node.feature] <= node.value:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.leaf_value\n",
    "    \n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node.leaf_value is not None:\n",
    "            print(depth * '  ' + 'Prediction', node.leaf_value)\n",
    "            return\n",
    "        print(depth * '  ' + 'Feature', node.feature, '<=', node.value, 'Info gain:', node.info_gain)\n",
    "        self.print_tree(node.left, depth + 1)\n",
    "        self.print_tree(node.right, depth + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "    \n",
    "    # get the indices of the test and train set\n",
    "    test_indices = np.random.choice(len(df), test_size, replace=False)\n",
    "    train_indices = np.array(list(set(range(len(df))) - set(test_indices)))\n",
    "\n",
    "    # split the dataframe into train and test sets\n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "\n",
    "    # convert the train and test sets into numpy arrays\n",
    "    X_train = train_df.drop('Churn', axis=1).values\n",
    "    y_train = train_df['Churn'].values\n",
    "    X_test = test_df.drop('Churn', axis=1).values\n",
    "    y_test = test_df['Churn'].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DECISION TREE IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Gain tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 decision trees with different criteria\n",
    "tree_info_gain = DecisionTree(min_samples_split=2, max_depth=3, criterion='info_gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Index tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_gini = DecisionTree(min_samples_split=2, max_depth=3, criterion='gini_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Ratio tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_gain_ratio = DecisionTree(min_samples_split=2, max_depth=3, criterion='gain_ratio')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tryEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
