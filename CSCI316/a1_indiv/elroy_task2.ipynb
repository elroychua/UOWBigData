{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1 Task 2\n",
    "\n",
    "<strong>Name:</strong> Elroy Chua Ming Xuan </br>\n",
    "<strong>UOW ID: </strong> 7431673 </br>\n",
    "<strong>Data set: </strong> https://www.kaggle.com/datasets/muhammadshahidazeem/customer-churn-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Implement three DT models by the split criteria of Information Gain, Gain Ratio and Gini Index. \n",
    "You can use either binary-split or multiple-split.\n",
    "Decision Tree models based on Information Gain, Gain Ratio, and Gini Index, you need to implement three different splitting criteria. All these criteria basically help in selecting the best feature for splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "eps = np.finfo(float).eps\n",
    "from numpy import log2 as log\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set warning message filter\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Usage Frequency</th>\n",
       "      <th>Support Calls</th>\n",
       "      <th>Payment Delay</th>\n",
       "      <th>Subscription Type</th>\n",
       "      <th>Contract Length</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Last Interaction</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Annual</td>\n",
       "      <td>932.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>557.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>185.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>396.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>617.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID   Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
       "0         2.0  30.0  Female    39.0             14.0            5.0   \n",
       "1         3.0  65.0  Female    49.0              1.0           10.0   \n",
       "2         4.0  55.0  Female    14.0              4.0            6.0   \n",
       "3         5.0  58.0    Male    38.0             21.0            7.0   \n",
       "4         6.0  23.0    Male    32.0             20.0            5.0   \n",
       "\n",
       "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
       "0           18.0          Standard          Annual        932.0   \n",
       "1            8.0             Basic         Monthly        557.0   \n",
       "2           18.0             Basic       Quarterly        185.0   \n",
       "3            7.0          Standard         Monthly        396.0   \n",
       "4            8.0             Basic         Monthly        617.0   \n",
       "\n",
       "   Last Interaction  Churn  \n",
       "0              17.0    1.0  \n",
       "1               6.0    1.0  \n",
       "2               3.0    1.0  \n",
       "3              29.0    1.0  \n",
       "4              20.0    1.0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('customer_churn_dataset-testing-master.csv')\n",
    "df_train = pd.read_csv('customer_churn_dataset-training-master.csv')\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505207 entries, 0 to 505206\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   CustomerID         505206 non-null  float64\n",
      " 1   Age                505206 non-null  float64\n",
      " 2   Gender             505206 non-null  object \n",
      " 3   Tenure             505206 non-null  float64\n",
      " 4   Usage Frequency    505206 non-null  float64\n",
      " 5   Support Calls      505206 non-null  float64\n",
      " 6   Payment Delay      505206 non-null  float64\n",
      " 7   Subscription Type  505206 non-null  object \n",
      " 8   Contract Length    505206 non-null  object \n",
      " 9   Total Spend        505206 non-null  float64\n",
      " 10  Last Interaction   505206 non-null  float64\n",
      " 11  Churn              505206 non-null  float64\n",
      "dtypes: float64(9), object(3)\n",
      "memory usage: 46.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Usage Frequency</th>\n",
       "      <th>Support Calls</th>\n",
       "      <th>Payment Delay</th>\n",
       "      <th>Total Spend</th>\n",
       "      <th>Last Interaction</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "      <td>505206.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200779.451782</td>\n",
       "      <td>39.704172</td>\n",
       "      <td>31.350435</td>\n",
       "      <td>15.714825</td>\n",
       "      <td>3.833317</td>\n",
       "      <td>13.496843</td>\n",
       "      <td>620.072766</td>\n",
       "      <td>14.610581</td>\n",
       "      <td>0.555203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>137241.343095</td>\n",
       "      <td>12.670577</td>\n",
       "      <td>17.237482</td>\n",
       "      <td>8.619323</td>\n",
       "      <td>3.133603</td>\n",
       "      <td>8.451187</td>\n",
       "      <td>245.319256</td>\n",
       "      <td>8.608286</td>\n",
       "      <td>0.496944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>63827.250000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>193039.500000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>648.900000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>321645.750000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>449999.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CustomerID            Age         Tenure  Usage Frequency  \\\n",
       "count  505206.000000  505206.000000  505206.000000    505206.000000   \n",
       "mean   200779.451782      39.704172      31.350435        15.714825   \n",
       "std    137241.343095      12.670577      17.237482         8.619323   \n",
       "min         1.000000      18.000000       1.000000         1.000000   \n",
       "25%     63827.250000      29.000000      16.000000         8.000000   \n",
       "50%    193039.500000      40.000000      32.000000        16.000000   \n",
       "75%    321645.750000      49.000000      46.000000        23.000000   \n",
       "max    449999.000000      65.000000      60.000000        30.000000   \n",
       "\n",
       "       Support Calls  Payment Delay    Total Spend  Last Interaction  \\\n",
       "count  505206.000000  505206.000000  505206.000000     505206.000000   \n",
       "mean        3.833317      13.496843     620.072766         14.610581   \n",
       "std         3.133603       8.451187     245.319256          8.608286   \n",
       "min         0.000000       0.000000     100.000000          1.000000   \n",
       "25%         1.000000       6.000000     446.000000          7.000000   \n",
       "50%         3.000000      13.000000     648.900000         14.000000   \n",
       "75%         6.000000      20.000000     824.000000         22.000000   \n",
       "max        10.000000      30.000000    1000.000000         30.000000   \n",
       "\n",
       "               Churn  \n",
       "count  505206.000000  \n",
       "mean        0.555203  \n",
       "std         0.496944  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         1.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data is pure\n",
    "def check_purity(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        potential_splits[column_index] = unique_values\n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    split_column_values = data[:, split_column]\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values > split_value]\n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mse(data):\n",
    "    actual_values = data[:,-1]\n",
    "    if len(actual_values) == 0:\n",
    "        mse = 0\n",
    "    else:\n",
    "        prediction = np.mean(actual_values)\n",
    "        mse = np.mean((actual_values - prediction)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_metric(data_below, data_above, metric_function):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    overall_metric = (p_data_below * metric_function(data_below) + p_data_above * metric_function(data_above))\n",
    "    return overall_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    #Add the model selection\n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=calculate_entropy)\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Entropy of dataset\n",
    "def findEntropy(df):\n",
    "    Class = df.keys()[-1] #To make the code generic, changing target variable class name\n",
    "    entropy = 0\n",
    "    values = df[Class].unique()\n",
    "    for value in values:\n",
    "        fraction = df[Class].value_counts()[value]/len(df[Class])\n",
    "        entropy += -fraction*np.log2(fraction)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Entroppy by attribute\n",
    "def findEntropyAttribute(df, attribute):\n",
    "    Class = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
    "\n",
    "    target_variables = df[Class].unique()  #This gives all 'Yes' and 'No'\n",
    "    variables = df[attribute].unique()    #This gives different features in that attribute (like 'Hot','Cold' in Temperature)\n",
    "\n",
    "    entropy2 = 0\n",
    "    min_entropy = -999\n",
    "    min_var_name = \"\"\n",
    "    \n",
    "    for variable in variables:\n",
    "        entropy = 0\n",
    "        for target_variable in target_variables:\n",
    "            num = len(df[attribute][df[attribute]==variable][df[Class] ==target_variable])\n",
    "            den = len(df[attribute][df[attribute]==variable])\n",
    "            fraction = num/(den+eps)\n",
    "            entropy += -fraction*log(fraction+eps)\n",
    "        fraction2 = den/len(df)\n",
    "        entropy2 += -fraction2*entropy\n",
    "\n",
    "        if(entropy >= min_entropy):\n",
    "            min_entropy = entropy\n",
    "            min_var_name = variable\n",
    "        \n",
    "    return abs(entropy2), min_var_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to determine gain ratio\n",
    "def findSplitInfo(df, attribute):\n",
    "\n",
    "    # Get the unique values of the attribute\n",
    "    variables = df[attribute].unique()\n",
    "    if (len(variables) == 1):\n",
    "        return 1\n",
    "    split_info = 0\n",
    "\n",
    "    for variable in variables:\n",
    "        d = len(df[df[attribute] == variable])/len(df)\n",
    "        split_info += -d * log(d)\n",
    "\n",
    "    return abs(split_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate information gain and return the best splitting node(feature)\n",
    "def infoGain(df, ratio=False):\n",
    "    df = pd.DataFrame(df, columns=[COLUMN_HEADERS])\n",
    "    IG=[]\n",
    "    var_names=[]\n",
    "    for key in df.keys()[:-1]:\n",
    "        val, var_name = findEntropyAttribute(df, key)\n",
    "        ig = findEntropy(df) - val\n",
    "        if(ratio):\n",
    "            split_info = findSplitInfo(df, key)\n",
    "            gain_ration = ig/split_info\n",
    "            IG.append(gain_ration)\n",
    "            var_names.append(var_name)\n",
    "        else:\n",
    "            IG.append(ig)\n",
    "            var_names.append(var_name)\n",
    "    best_ig_index= np.argmax(IG)\n",
    "    return best_ig_index, var_names[best_ig_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniImpurity2(valueCounts):\n",
    "    n = valueCounts.sum()\n",
    "    p_sum=0\n",
    "    for key in valueCounts.keys():\n",
    "        p_sum = p_sum + (valueCounts[key]/n) * (valueCounts[key]/n)\n",
    "        gini = 1 - p_sum\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniSplitAtt2(df, attName):\n",
    "    attValues= df[attName].value_counts()\n",
    "    gini_A = 0\n",
    "    min_impurity = 999\n",
    "    min_impurity_variable = \"\"\n",
    "    for key in attValues.keys():\n",
    "        dfKey = df[df.keys()[-1]][df[attName] == key].value_counts()\n",
    "        numOfKey = attValues[key]\n",
    "        n = df.shape[0]\n",
    "        impurity = ((numOfKey/n) * giniImpurity2(dfKey))\n",
    "        if(impurity <= min_impurity):\n",
    "            min_impurity = impurity\n",
    "            min_impurity_variable = key\n",
    "        gini_A = gini_A + impurity\n",
    "    return gini_A, min_impurity_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniIndex2(df, attributeNames):\n",
    "    df = pd.DataFrame(df, columns=COLUMN_HEADERS)\n",
    "    giniAttribute={}\n",
    "    minValue= sys.maxsize\n",
    "    counter=0\n",
    "    for key in attributeNames:\n",
    "        giniAttribute[key] = [*giniSplitAtt2(df, key)]\n",
    "        if minValue > giniAttribute[key][0]:\n",
    "            minValue = giniAttribute[key][0]\n",
    "            selectedAttribute = counter\n",
    "            selectedVariable = giniAttribute[key][1]\n",
    "        counter+=1\n",
    "    return selectedAttribute, selectedVariable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5, model='infoGain'):\n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df\n",
    "\n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data, model)\n",
    "        return classification\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "        #Based on model, determine the best split and value to split on\n",
    "        if model == 'infoGain':\n",
    "            split_column, split_value = infoGain(data)\n",
    "        elif model == 'gainRatio':\n",
    "            split_column, split_value = infoGain(data, True)\n",
    "        elif model == 'gini':\n",
    "            split_column, split_value = giniIndex2(data, COLUMN_HEADERS[:-1])\n",
    "        \n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "    \n",
    "    #determine question\n",
    "    feature_name = COLUMN_HEADERS[split_column]\n",
    "    question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "    #instantiate sub-tree\n",
    "    sub_tree = {question: []}\n",
    "\n",
    "    #find answers (recursion)\n",
    "    yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth, model)\n",
    "    no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth, model)\n",
    "\n",
    "    #if the answers are the same, then there is no point in asking the question\n",
    "    if yes_answer == no_answer:\n",
    "        sub_tree = yes_answer\n",
    "    else:\n",
    "        sub_tree[question].append(yes_answer)\n",
    "        sub_tree[question].append(no_answer)\n",
    "    \n",
    "    return sub_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#Show example of decision tree created\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, max_depth\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minfoGain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m pprint(tree)\n",
      "Cell \u001b[0;32mIn[113], line 21\u001b[0m, in \u001b[0;36mdecision_tree_algorithm\u001b[0;34m(df, counter, min_samples, max_depth, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#Based on model, determine the best split and value to split on\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minfoGain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data)\n\u001b[1;32m     22\u001b[0m \u001b[39melif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgainRatio\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     23\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data, \u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[109], line 7\u001b[0m, in \u001b[0;36minfoGain\u001b[0;34m(df, ratio)\u001b[0m\n\u001b[1;32m      5\u001b[0m var_names\u001b[39m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mkeys()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     val, var_name \u001b[39m=\u001b[39m findEntropyAttribute(df, key)\n\u001b[1;32m      8\u001b[0m     ig \u001b[39m=\u001b[39m findEntropy(df) \u001b[39m-\u001b[39m val\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m(ratio):\n",
      "Cell \u001b[0;32mIn[107], line 16\u001b[0m, in \u001b[0;36mfindEntropyAttribute\u001b[0;34m(df, attribute)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m target_variable \u001b[39min\u001b[39;00m target_variables:\n\u001b[1;32m     15\u001b[0m     num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39mvariable][df[Class] \u001b[39m==\u001b[39mtarget_variable])\n\u001b[0;32m---> 16\u001b[0m     den \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39;49mvariable])\n\u001b[1;32m     17\u001b[0m     fraction \u001b[39m=\u001b[39m num\u001b[39m/\u001b[39m(den\u001b[39m+\u001b[39meps)\n\u001b[1;32m     18\u001b[0m     entropy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mfraction\u001b[39m*\u001b[39mlog(fraction\u001b[39m+\u001b[39meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6098\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     83\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Show example of decision tree created\n",
    "tree = decision_tree_algorithm(train_df, max_depth=3, model='infoGain')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=3,model='gainRatio')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=3, model='gini')\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    if str(example[feature_name]) == value:\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "    \n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    #recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df, tree):\n",
    "    if len(df) != 0:\n",
    "        predictions = df.apply(predict_example, args=(tree,), axis=1)\n",
    "    else:\n",
    "        predictions = pd.Series()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_example(example, tree):\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    if str(example[feature_name]) == value:\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "    \n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1)\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"target\"]\n",
    "\n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, remain_df = train_test_split(df, test_size=0.4) #splits the data into 60% training and 40% testing\n",
    "test_df, prune_df = train_test_split(remain_df, test_size=0.5) #splits the remaining 40% into 20% testing and 20% validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ig_tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, max_depth\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minfoGain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m gr_tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgainRatio\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m gini_tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, max_depth\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[113], line 21\u001b[0m, in \u001b[0;36mdecision_tree_algorithm\u001b[0;34m(df, counter, min_samples, max_depth, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#Based on model, determine the best split and value to split on\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minfoGain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data)\n\u001b[1;32m     22\u001b[0m \u001b[39melif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgainRatio\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     23\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data, \u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[109], line 7\u001b[0m, in \u001b[0;36minfoGain\u001b[0;34m(df, ratio)\u001b[0m\n\u001b[1;32m      5\u001b[0m var_names\u001b[39m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mkeys()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     val, var_name \u001b[39m=\u001b[39m findEntropyAttribute(df, key)\n\u001b[1;32m      8\u001b[0m     ig \u001b[39m=\u001b[39m findEntropy(df) \u001b[39m-\u001b[39m val\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m(ratio):\n",
      "Cell \u001b[0;32mIn[107], line 15\u001b[0m, in \u001b[0;36mfindEntropyAttribute\u001b[0;34m(df, attribute)\u001b[0m\n\u001b[1;32m     13\u001b[0m entropy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m target_variable \u001b[39min\u001b[39;00m target_variables:\n\u001b[0;32m---> 15\u001b[0m     num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39;49mvariable][df[Class] \u001b[39m==\u001b[39mtarget_variable])\n\u001b[1;32m     16\u001b[0m     den \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39mvariable])\n\u001b[1;32m     17\u001b[0m     fraction \u001b[39m=\u001b[39m num\u001b[39m/\u001b[39m(den\u001b[39m+\u001b[39meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/series.py:1029\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m   1028\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1029\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex, key)\n\u001b[1;32m   1030\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1031\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/indexing.py:2518\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2515\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(result\u001b[39m.\u001b[39mdtype):\n\u001b[1;32m   2516\u001b[0m         \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mastype(\u001b[39mbool\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 2518\u001b[0m \u001b[39mif\u001b[39;00m is_object_dtype(key):\n\u001b[1;32m   2519\u001b[0m     \u001b[39m# key might be object-dtype bool, check_array_indexer needs bool array\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(result, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   2521\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_array_like(result):\n\u001b[1;32m   2522\u001b[0m     \u001b[39m# GH 33924\u001b[39;00m\n\u001b[1;32m   2523\u001b[0m     \u001b[39m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/dtypes/common.py:158\u001b[0m, in \u001b[0;36mis_object_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39m    Evaluate if the tipo is a subclass of the klasses\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39m    and not a datetimelike.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m tipo: (\n\u001b[1;32m    153\u001b[0m         \u001b[39missubclass\u001b[39m(tipo, klasses)\n\u001b[1;32m    154\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39missubclass\u001b[39m(tipo, (np\u001b[39m.\u001b[39mdatetime64, np\u001b[39m.\u001b[39mtimedelta64))\n\u001b[1;32m    155\u001b[0m     )\n\u001b[0;32m--> 158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_object_dtype\u001b[39m(arr_or_dtype) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    159\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39m    Check whether an array-like or dtype is of the object dtype.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m    False\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m _is_dtype_type(arr_or_dtype, classes(np\u001b[39m.\u001b[39mobject_))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ig_tree = decision_tree_algorithm(train_df, max_depth=10, model='infoGain')\n",
    "gr_tree = decision_tree_algorithm(train_df, max_depth=10,model='gainRatio')\n",
    "gini_tree = decision_tree_algorithm(train_df, max_depth=10,model='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Info Gain Tree Accuracy : {calculate_accuracy(test_df,ig_tree)}\")\n",
    "print(f\"Gain Ratio Tree Accuracy : {calculate_accuracy(test_df,gr_tree)}\")\n",
    "print(f\"Gini Index Tree Accuracy : {calculate_accuracy(test_df,gini_tree)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Pruning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, question): \n",
    "    feature, comparison_operator, value = question.split() \n",
    "    df_yes = df[df[feature].astype(str) == value] \n",
    "    df_no = df[df[feature].astype(str) != value] \n",
    "    return df_yes, df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_leaf(df_train): \n",
    "    return df_train.target.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_errors(df_val, tree): \n",
    "    predictions = make_predictions(df_val, tree) \n",
    "    actual_values = df_val.target \n",
    "    return sum(predictions != actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_result(tree, df_train, df_val): \n",
    "    leaf = determine_leaf(df_train) \n",
    "    errors_leaf = determine_errors(df_val, leaf) \n",
    "    errors_decision_node = determine_errors(df_val, tree) \n",
    "    if errors_leaf <= errors_decision_node: \n",
    "        return leaf \n",
    "    else: \n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_pruning(tree, df_train, df_val): \n",
    "    question = list(tree.keys())[0] \n",
    "    yes_answer, no_answer = tree[question]\n",
    "\n",
    "    #base case\n",
    "    if not isinstance(yes_answer, dict) and not isinstance(no_answer, dict):\n",
    "        return pruning_result(tree, df_train, df_val)\n",
    "    #recursive case\n",
    "    else: \n",
    "        df_train_yes, df_train_no = filter_df(df_train, question) \n",
    "        df_val_yes, df_val_no = filter_df(df_val, question) \n",
    "        \n",
    "        if isinstance(yes_answer, dict): \n",
    "            yes_answer = post_pruning(yes_answer, df_train_yes, df_val_yes) \n",
    "        if isinstance(no_answer, dict): \n",
    "            no_answer = post_pruning(no_answer, df_train_no, df_val_no) \n",
    "        tree = {question: [yes_answer, no_answer]} \n",
    "        \n",
    "        return pruning_result(tree, df_train, df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the best depth for each model\n",
    "#### Info Gain Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[134], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m: [], \u001b[39m\"\u001b[39m\u001b[39macc_tree\u001b[39m\u001b[39m\"\u001b[39m: [], \u001b[39m\"\u001b[39m\u001b[39macc_tree_pruned\u001b[39m\u001b[39m\"\u001b[39m: []}\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m20\u001b[39m): \n\u001b[0;32m----> 3\u001b[0m     tree \u001b[39m=\u001b[39m decision_tree_algorithm(train_df, max_depth\u001b[39m=\u001b[39;49mn, model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39minfoGain\u001b[39;49m\u001b[39m'\u001b[39;49m) \n\u001b[1;32m      4\u001b[0m     tree_pruned \u001b[39m=\u001b[39m post_pruning(tree, train_df, prune_df) \n\u001b[1;32m      5\u001b[0m     metrics[\u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(n) \n",
      "Cell \u001b[0;32mIn[113], line 21\u001b[0m, in \u001b[0;36mdecision_tree_algorithm\u001b[0;34m(df, counter, min_samples, max_depth, model)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m#Based on model, determine the best split and value to split on\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minfoGain\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data)\n\u001b[1;32m     22\u001b[0m \u001b[39melif\u001b[39;00m model \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgainRatio\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     23\u001b[0m     split_column, split_value \u001b[39m=\u001b[39m infoGain(data, \u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[109], line 7\u001b[0m, in \u001b[0;36minfoGain\u001b[0;34m(df, ratio)\u001b[0m\n\u001b[1;32m      5\u001b[0m var_names\u001b[39m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39mkeys()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]:\n\u001b[0;32m----> 7\u001b[0m     val, var_name \u001b[39m=\u001b[39m findEntropyAttribute(df, key)\n\u001b[1;32m      8\u001b[0m     ig \u001b[39m=\u001b[39m findEntropy(df) \u001b[39m-\u001b[39m val\n\u001b[1;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m(ratio):\n",
      "Cell \u001b[0;32mIn[107], line 16\u001b[0m, in \u001b[0;36mfindEntropyAttribute\u001b[0;34m(df, attribute)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m target_variable \u001b[39min\u001b[39;00m target_variables:\n\u001b[1;32m     15\u001b[0m     num \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39mvariable][df[Class] \u001b[39m==\u001b[39mtarget_variable])\n\u001b[0;32m---> 16\u001b[0m     den \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df[attribute][df[attribute]\u001b[39m==\u001b[39;49mvariable])\n\u001b[1;32m     17\u001b[0m     fraction \u001b[39m=\u001b[39m num\u001b[39m/\u001b[39m(den\u001b[39m+\u001b[39meps)\n\u001b[1;32m     18\u001b[0m     entropy \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39mfraction\u001b[39m*\u001b[39mlog(fraction\u001b[39m+\u001b[39meps)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[1;32m   6098\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    295\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/testEnv/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[1;32m     83\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = {\"max_depth\": [], \"acc_tree\": [], \"acc_tree_pruned\": []}\n",
    "for n in range(5, 20): \n",
    "    tree = decision_tree_algorithm(train_df, max_depth=n, model='infoGain') \n",
    "    tree_pruned = post_pruning(tree, train_df, prune_df) \n",
    "    metrics[\"max_depth\"].append(n) \n",
    "    metrics[\"acc_tree\"].append(calculate_accuracy(test_df, tree)) \n",
    "    metrics[\"acc_tree_pruned\"].append(calculate_accuracy(test_df, tree_pruned)) \n",
    "\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics = df_metrics.set_index(\"max_depth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of best accuracy\n",
    "index = np.argmax(metrics['acc_tree_pruned'])\n",
    "accuracy = max(metrics['acc_tree_pruned'])\n",
    "\n",
    "# Depth at which max pruned tree accuracy is acheived\n",
    "best_depth = metrics['max_depth'][index]\n",
    "\n",
    "infoGainAccuracy = [accuracy, best_depth]\n",
    "\n",
    "print(\n",
    "    f\"Best accuracy for pruned Info Gain Decision Tree is acheived at: \\nMax depth : {best_depth}\\nAccuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gain Ratio Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\"max_depth\": [], \"acc_tree\": [], \"acc_tree_pruned\": []}\n",
    "for n in range(5, 20): \n",
    "    tree = decision_tree_algorithm(train_df, max_depth=n, model='gainRatio') \n",
    "    tree_pruned = post_pruning(tree, train_df, prune_df) \n",
    "    \n",
    "    metrics[\"max_depth\"].append(n) \n",
    "    metrics[\"acc_tree\"].append(calculate_accuracy(test_df, tree)) \n",
    "    metrics[\"acc_tree_pruned\"].append(calculate_accuracy(test_df, tree_pruned)) \n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics = df_metrics.set_index(\"max_depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.plot(figsize=(12, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index of best accuracy\n",
    "index = np.argmax(metrics['acc_tree_pruned'])\n",
    "accuracy = max(metrics['acc_tree_pruned'])\n",
    "\n",
    "#Depth at which max pruned tree accuracy is achieved\n",
    "best_depth = metrics['max_depth'][index]\n",
    "\n",
    "gainRatioAccuracy =[accuracy, best_depth]\n",
    "print(\n",
    "    f\"Best accuracy for pruned Gain Ratio Decision Tree is acheived at: \\nMax depth : {best_depth}\\nAccuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('testEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96f8c630555ca8c8517ffff7a44c42c100b07707e04e471dc387e2341790e389"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
