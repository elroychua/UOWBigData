{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2 Task 1\n",
    "\n",
    "<strong>Name:</strong> Elroy Chua Ming Xuan </br>\n",
    "<strong>UOW ID: </strong> 7431673 </br>\n",
    "<strong>Data set: </strong> https://www.kaggle.com/datasets/muhammadshahidazeem/customer-churn-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import Necessary Libraries and Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505207 entries, 0 to 505206\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   CustomerID         505206 non-null  float64\n",
      " 1   Age                505206 non-null  float64\n",
      " 2   Gender             505206 non-null  object \n",
      " 3   Tenure             505206 non-null  float64\n",
      " 4   Usage Frequency    505206 non-null  float64\n",
      " 5   Support Calls      505206 non-null  float64\n",
      " 6   Payment Delay      505206 non-null  float64\n",
      " 7   Subscription Type  505206 non-null  object \n",
      " 8   Contract Length    505206 non-null  object \n",
      " 9   Total Spend        505206 non-null  float64\n",
      " 10  Last Interaction   505206 non-null  float64\n",
      " 11  Churn              505206 non-null  float64\n",
      "dtypes: float64(9), object(3)\n",
      "memory usage: 46.3+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Import data\n",
    "train_df = pd.read_csv('customer_churn_dataset-training-master.csv')\n",
    "test_df = pd.read_csv('customer_churn_dataset-testing-master.csv')\n",
    "\n",
    "# Concatenate train and test data\n",
    "df = pd.concat([train_df, test_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Get info on data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Explore and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505206 entries, 0 to 505206\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   CustomerID         505206 non-null  int64 \n",
      " 1   Age                505206 non-null  int64 \n",
      " 2   Gender             505206 non-null  object\n",
      " 3   Tenure             505206 non-null  int64 \n",
      " 4   Usage Frequency    505206 non-null  int64 \n",
      " 5   Support Calls      505206 non-null  int64 \n",
      " 6   Payment Delay      505206 non-null  int64 \n",
      " 7   Subscription Type  505206 non-null  object\n",
      " 8   Contract Length    505206 non-null  object\n",
      " 9   Total Spend        505206 non-null  int64 \n",
      " 10  Last Interaction   505206 non-null  int64 \n",
      " 11  Churn              505206 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 50.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Delete the single null row\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert the feature types back to int64\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'float64':\n",
    "        df[col] = df[col].astype('int64')\n",
    "\n",
    "# Check for missing values inside the data sets\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: One Hot Encoding nominal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CustomerID  Age  Tenure  Usage Frequency  Support Calls  Payment Delay  \\\n",
      "0           2   30      39               14              5             18   \n",
      "1           3   65      49                1             10              8   \n",
      "2           4   55      14                4              6             18   \n",
      "3           5   58      38               21              7              7   \n",
      "4           6   23      32               20              5              8   \n",
      "\n",
      "   Total Spend  Last Interaction  Churn  Gender_Female  Gender_Male  \\\n",
      "0          932                17      1              1            0   \n",
      "1          557                 6      1              1            0   \n",
      "2          185                 3      1              1            0   \n",
      "3          396                29      1              0            1   \n",
      "4          617                20      1              0            1   \n",
      "\n",
      "   Subscription Type_Basic  Subscription Type_Premium  \\\n",
      "0                        0                          0   \n",
      "1                        1                          0   \n",
      "2                        1                          0   \n",
      "3                        0                          0   \n",
      "4                        1                          0   \n",
      "\n",
      "   Subscription Type_Standard  Contract Length_Annual  \\\n",
      "0                           1                       1   \n",
      "1                           0                       0   \n",
      "2                           0                       0   \n",
      "3                           1                       0   \n",
      "4                           0                       0   \n",
      "\n",
      "   Contract Length_Monthly  Contract Length_Quarterly  \n",
      "0                        0                          0  \n",
      "1                        1                          0  \n",
      "2                        0                          1  \n",
      "3                        1                          0  \n",
      "4                        1                          0  \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 505206 entries, 0 to 505206\n",
      "Data columns (total 17 columns):\n",
      " #   Column                      Non-Null Count   Dtype\n",
      "---  ------                      --------------   -----\n",
      " 0   CustomerID                  505206 non-null  int64\n",
      " 1   Age                         505206 non-null  int64\n",
      " 2   Tenure                      505206 non-null  int64\n",
      " 3   Usage Frequency             505206 non-null  int64\n",
      " 4   Support Calls               505206 non-null  int64\n",
      " 5   Payment Delay               505206 non-null  int64\n",
      " 6   Total Spend                 505206 non-null  int64\n",
      " 7   Last Interaction            505206 non-null  int64\n",
      " 8   Churn                       505206 non-null  int64\n",
      " 9   Gender_Female               505206 non-null  int64\n",
      " 10  Gender_Male                 505206 non-null  int64\n",
      " 11  Subscription Type_Basic     505206 non-null  int64\n",
      " 12  Subscription Type_Premium   505206 non-null  int64\n",
      " 13  Subscription Type_Standard  505206 non-null  int64\n",
      " 14  Contract Length_Annual      505206 non-null  int64\n",
      " 15  Contract Length_Monthly     505206 non-null  int64\n",
      " 16  Contract Length_Quarterly   505206 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 69.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(\n",
    "    df, columns=['Gender', 'Subscription Type', 'Contract Length'], dtype='int64')\n",
    "\n",
    "print(df_encoded.head())\n",
    "print()\n",
    "df_encoded.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Implement Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE NODE CLASS\n",
    "class Node:\n",
    "    def __init__(self, feature=None, value=None, left=None, right=None, info_gain=None, leaf_value=None):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "\n",
    "        # leaf nodes\n",
    "        self.leaf_value = leaf_value\n",
    "\n",
    "# DEFINE DECISION TREE CLASS\n",
    "\n",
    "\n",
    "class DecisionTree():\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, criterion='info_gain'):\n",
    "        self.root = None\n",
    "        # stopping conditions\n",
    "        # minimum number of samples required to split an internal node\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth  # maximum depth of the tree\n",
    "        # criterion to measure the quality of a split (gini_index, gain_ratio, info_gain)\n",
    "        self.criterion = criterion\n",
    "\n",
    "    # TYPES OF CRITERION:\n",
    "    # FOR INFO GAIN\n",
    "    def entropy(self, y):\n",
    "        entropy = 0\n",
    "        unique_values = set(y)\n",
    "\n",
    "        # get the probability of each value\n",
    "        for value in unique_values:\n",
    "            p = sum(y == value) / len(y)\n",
    "            entropy -= p * np.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def information_gain(self, y, y_left, y_right):\n",
    "        entropy_parent = self.entropy(y)\n",
    "        entropy_children = (len(y_left) / len(y)) * self.entropy(y_left) + \\\n",
    "            (len(y_right) / len(y)) * self.entropy(y_right)\n",
    "        return entropy_parent - entropy_children\n",
    "\n",
    "    # FOR GINI INDEX\n",
    "    def gini_index(self, y):\n",
    "        gini_index = 1\n",
    "        unique_values = set(y)\n",
    "\n",
    "        # get the probability of each value\n",
    "        for value in unique_values:\n",
    "            p = sum(y == value) / len(y)\n",
    "            gini_index -= p ** 2\n",
    "        return gini_index\n",
    "\n",
    "    # FOR GAIN RATIO\n",
    "    def gain_ratio(self, y, y_left, y_right):\n",
    "        information_gain = self.information_gain(y, y_left, y_right)\n",
    "        split_info = self.entropy(y)\n",
    "        return information_gain / split_info\n",
    "\n",
    "    def best_split(self, X, y):\n",
    "        # best_split = (feature index, split value, information gain)\n",
    "        best_split = (None, None, 0)\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            X_feature = X[:, feature]\n",
    "            unique_values = set(X_feature)\n",
    "            for value in unique_values:\n",
    "                y_left = y[X_feature <= value]\n",
    "                y_right = y[X_feature > value]\n",
    "                if self.criterion == 'gini_index':\n",
    "                    info_gain = self.gini_index(y) - (len(y_left) / len(y)) * self.gini_index(\n",
    "                        y_left) - (len(y_right) / len(y)) * self.gini_index(y_right)\n",
    "                elif self.criterion == 'gain_ratio':\n",
    "                    info_gain = self.gain_ratio(y, y_left, y_right)\n",
    "                elif self.criterion == 'info_gain':\n",
    "                    info_gain = self.information_gain(y, y_left, y_right)\n",
    "                else:\n",
    "                    raise ValueError('Invalid criterion')\n",
    "                if info_gain > best_split[2]:\n",
    "                    best_split = (feature, value, info_gain)\n",
    "        return best_split\n",
    "\n",
    "    def build_tree(self, X, y, depth=0):\n",
    "        # Prevent further splitting if stopping conditions are met\n",
    "        if (depth >= self.max_depth) or (len(y) < self.min_samples_split) or (len(np.unique(y)) == 1):\n",
    "            # Convert y to integers before using bincount\n",
    "            leaf_value = np.bincount(y.astype(int)).argmax()\n",
    "            return Node(leaf_value=leaf_value)\n",
    "\n",
    "        # Continue splitting the data if stopping conditions are not met\n",
    "        feature, value, info_gain = self.best_split(\n",
    "            X, y)  # find the best split point\n",
    "        X_left, y_left = X[X[:, feature] <= value], y[X[:, feature] <= value]\n",
    "        X_right, y_right = X[X[:, feature] > value], y[X[:, feature] > value]\n",
    "\n",
    "        # Recursively build the subtrees\n",
    "        left = self.build_tree(X_left, y_left, depth + 1)\n",
    "        right = self.build_tree(X_right, y_right, depth + 1)\n",
    "        return Node(feature=feature, value=value, left=left, right=right, info_gain=info_gain)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self.build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    def _predict(self, x):\n",
    "        node = self.root\n",
    "        while node.leaf_value is None:\n",
    "            if x[node.feature] <= node.value:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.leaf_value\n",
    "\n",
    "    def print_tree(self, node=None, depth=0):\n",
    "        if node is None:\n",
    "            node = self.root\n",
    "        if node.leaf_value is not None:\n",
    "            print(depth * '  ' + 'Prediction', node.leaf_value)\n",
    "            return\n",
    "        print(depth * '  ' + 'Feature', node.feature, '<=',\n",
    "              node.value, 'Info gain:', node.info_gain)\n",
    "        self.print_tree(node.left, depth + 1)\n",
    "        self.print_tree(node.right, depth + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Implement Random Forest Classifier\n",
    "1. Bootstrapping\n",
    "2. Feature Selection\n",
    "3. Tree Construction\n",
    "4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_samples_split=2, n_feature=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.n_features = n_feature\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTree(max_depth=self.max_depth,\n",
    "                                min_samples_split=self.min_samples_split)\n",
    "            X_sample, y_sample = self._bootstrap_samples(X, y)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def _bootstrap_samples(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "        return X[idxs], y[idxs]\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
    "        tree_preds = np.swapaxes(predictions, 0, 1)\n",
    "        predictions = np.array([self._most_common_label(pred)\n",
    "                               for pred in tree_preds])\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 20% of the data\n",
    "df = df.sample(frac=0.1, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Splitting the Dataset into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size=0.2):\n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    # get the indices of the test and train set\n",
    "    test_indices = np.random.choice(len(df), test_size, replace=False)\n",
    "    train_indices = np.array(list(set(range(len(df))) - set(test_indices)))\n",
    "\n",
    "    # split the dataframe into train and test sets\n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "\n",
    "    # convert the train and test sets into numpy arrays\n",
    "    X_train = train_df.drop('Churn', axis=1).values\n",
    "    y_train = train_df['Churn'].values\n",
    "    X_test = test_df.drop('Churn', axis=1).values\n",
    "    y_test = test_df['Churn'].values\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 8: Train the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9314133016627079\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "clf = RandomForest(n_trees=10)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy(y_test, predictions)\n",
    "print(acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result:\n",
    "We can see that the accuracy from Random Forest is 0.931413304 with df.sample of 1, n_trees of 10, and runtime of 377m 15.9s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
