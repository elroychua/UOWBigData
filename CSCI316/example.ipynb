{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_321.jdk/Contents/Home\n",
      "22/02/25 15:23:29 WARN Utils: Your hostname, Adriels-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.2.53 instead (on interface en0)\n",
      "22/02/25 15:23:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /___/ .__/\\_,_/_/ /_/\\_\\   version 3.2.0\n",
      "      /_/\n",
      "                        \n",
      "Using Scala version 2.12.15, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_321\n",
      "Branch HEAD\n",
      "Compiled by user ubuntu on 2021-10-06T12:46:30Z\n",
      "Revision 5d45a415f3a29898d92380380cfd82bfc7f579ea\n",
      "Url https://github.com/apache/spark\n",
      "Type --help for more information.\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_321.jdk/Contents/Home\n",
    "\n",
    "!spark-submit --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/25 15:25:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "22/02/25 15:25:19 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|           0.0|  0.0|(692,[95,96,97,12...|\n",
      "|           0.0|  0.0|(692,[100,101,102...|\n",
      "|           0.0|  0.0|(692,[123,124,125...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "|           0.0|  0.0|(692,[124,125,126...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_5f5bbe0eb83f, numTrees=10, numClasses=2, numFeatures=692\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Random Forest Classifier Example.\n",
    "\"\"\"\n",
    "# $example on$\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# $example off$\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"RandomForestClassifierExample\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # $example on$\n",
    "    # Load and parse the data file, converting it to a DataFrame.\n",
    "    data = spark.read.format(\"libsvm\").load(\"example_data.txt\")\n",
    "\n",
    "    # Index labels, adding metadata to the label column.\n",
    "    # Fit on whole dataset to include all labels in index.\n",
    "    labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "    # Automatically identify categorical features, and index them.\n",
    "    # Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "    featureIndexer =\\\n",
    "        VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "    # Split the data into training and test sets (30% held out for testing)\n",
    "    (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "    # Train a RandomForest model.\n",
    "    rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "    # Convert indexed labels back to original labels.\n",
    "    labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                                   labels=labelIndexer.labels)\n",
    "\n",
    "    # Chain indexers and forest in a Pipeline\n",
    "    pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "    # Train model.  This also runs the indexers.\n",
    "    model = pipeline.fit(trainingData)\n",
    "\n",
    "    # Make predictions.\n",
    "    predictions = model.transform(testData)\n",
    "\n",
    "    # Select example rows to display.\n",
    "    predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "    # Select (prediction, true label) and compute test error\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "    print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "    rfModel = model.stages[2]\n",
    "    print(rfModel)  # summary only\n",
    "    # $example off$\n",
    "\n",
    "    spark.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 2.7.16 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
