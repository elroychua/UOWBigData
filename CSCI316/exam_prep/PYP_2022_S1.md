# Final Examination Paper Session 1 2022

## Question 1: Python Programming

Given a list named X which contains words (as strings), implement a Python function to compute the word(s) with the highest frequency in X. Write down the Python code.

```python
def find_highest_freq_word(X):
    word_dictionary = {}

    # Count the frequency of each word in the list
    for word in X:
        if word not in word_dictionary:
            word_dictionary[word] = 1
        else:
            word_dictionary[word] += 1

    # Find the maximum frequency
    max_frequency = max(word_dictionary.values())

    # Find the word(s) with the maximum frequency
    most_frequent_words = [word for word, frequency in word_dictionary.items() if frequency == max_frequency]

    return most_frequent_words
```

## Question 2: Pre-processing

## Question 3: DT - Gini Index, InfoGain, Gain Ratio

1. Gini Index uses Probability:

```
   P(sizeOfClass| avg) = 2/8
   P(sizeOfClass| avg & studentSat| low) = 1/2
   P(sizeOfClass| avg & studentSat| high) = 1/2
   gini index = 1 - (1/2)^2 + (1/2)^2 = 0.5

   P(sizeOfClass| small) = 4/8
   P(sizeOfClass| small & studentSat| low) = 2/4
   P(sizeOfClass| small & studentSat| high) = 2/4
   gini index = 1 - (2/4)^2 + (2/4)^2 = 0.5

   gini index for size of class = (2/8 _ 0.5) + (2/8 _ 0.5) + (4.8 \* 0.5) = 0.5
```

2. InfoGain uses Entropy (Shanon Entropy):

```
   Step 1: Calculate Entropy of Class
   E(buysComputer = "yes") = -9/14 X log2(9/14)
                           = 0.410
   E(buysComputer = "no") = -5/14 x log2(5/14)
                          = 0.53
   E(buysComputer) = E(buysComputer = "yes") + E(buysComputer = "no")
                   = 0.940
   Step 2: Calcualte Entropy for Feature

   E(buysComputer="yes", student="yes") = -6/7 * log2(6/7) = 0.191
   E(buysComputer="no", student="yes") = -1/7 * log2(1/7) = 0.401
   E(buysComputer="yes", student="no") = -3/7 * log2(3/7) = 0.524
   E(buysComputer="no", student="no") = -4/7 * log2(4/7) = 0.461

   E(buysComputer, student ="yes") = E(buysComputer="yes", student="yes") + E(buysComputer="no", student="yes")
                                    = 0.191 + 0.401 = 0.591
  E(buysComputer, student="no") = E(buysComputer="yes", student="no") + E(buysComputer="no", student="no")
                                = 0.524 + 0.461 = 0.985

   Step 3: Calculate InfoGain
   IG(buysComputer, student) = E(buysComputer) - [7/14 * E(buysComputer, student ="yes") + 7/14 * E(buysComputer, student="no") ]
                             = 0.940 - [7/14 * 0.591 + 7/14 * 0.985]
                             = 0.151
```

## Question 4: Naive Bayes

## Question 5: Apache Spark

## Question 6: ANN
